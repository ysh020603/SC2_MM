{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单元格 1: 加载模型和分词器\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# 假设 config.py 和 model.py 在同一个目录下或在 Python 路径中\n",
    "import config\n",
    "from model import Qwen2ForSC2Fusion\n",
    "\n",
    "def load_model_and_tokenizer():\n",
    "    \"\"\"\n",
    "    加载并初始化 SC2Fusion 模型和分词器。\n",
    "    返回:\n",
    "        tuple: (model, tokenizer)\n",
    "    \"\"\"\n",
    "    # --- 1. 设置模型路径 ---\n",
    "    # 请确保这个路径是正确的\n",
    "    save_path = '/data4/SC2/SC2_units_token_compress/model/Qwen_1_5B_MLP_modify_4_epochs'\n",
    "    print(f\"正在从 '{save_path}' 加载已训练的模型...\")\n",
    "\n",
    "    # --- 2. 加载分词器 ---\n",
    "    # 使用 use_fast=False 避免 tokenizer.json 的潜在问题\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\n",
    "            save_path,\n",
    "            trust_remote_code=True,\n",
    "            local_files_only=True,\n",
    "            use_fast=False  # 绕过 fast tokenizer 的加载问题\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"加载分词器时出错: {e}\")\n",
    "        raise\n",
    "\n",
    "    # --- 3. 加载自定义模型 ---\n",
    "    model = Qwen2ForSC2Fusion.from_pretrained(\n",
    "        save_path,\n",
    "        entity_vector_dim=config.ENTITY_VECTOR_DIM, # 提供自定义参数\n",
    "        trust_remote_code=True,\n",
    "        local_files_only=True\n",
    "    )\n",
    "\n",
    "    # --- 4. 初始化模型 ---\n",
    "    sc2_token_id = tokenizer.convert_tokens_to_ids(config.SC2_ENTITY_TOKEN)\n",
    "    model.sc2_entity_token_id = sc2_token_id\n",
    "\n",
    "    device = torch.device(config.DEVICE)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(\"模型和分词器加载成功！\")\n",
    "    return model, tokenizer\n",
    "\n",
    "# --- 执行加载 ---\n",
    "# model 和 tokenizer 变量将在此单元格的全局作用域中可用\n",
    "model, tokenizer = load_model_and_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =   {\n",
    "    \"encode\": [\n",
    "      1,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      1,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      1,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0,\n",
    "      0\n",
    "    ],\n",
    "    \"text_dict\": {\n",
    "      \"if_ours\": true,\n",
    "      \"name\": \"MissileTurret\",\n",
    "      \"health\": 0,\n",
    "      \"Position\": {\n",
    "        \"x\": 0,\n",
    "        \"y\": 40\n",
    "      }\n",
    "    }\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "实体向量维度: 83\n",
      "正在生成回复...\n",
      "\n",
      "==================================================\n",
      "输入 Prompt:\n",
      "<sc2_entity>\n",
      " 以上是一个 星际争霸场景的entity，请你描述一下 这个entity的状态\n",
      "\n",
      "==================================================\n",
      "模型生成结果:\n",
      "或者属性。 航空母\n",
      "\n",
      "一艘 航空母·\n",
      "\n",
      "在 星际争霸场景·\n",
      "\n",
      "中处于 昏暗的光线·\n",
      "\n",
      "下。// 航空母·\n",
      "\n",
      "可以发射 航空母炮·\n",
      "\n",
      "。// 航空母炮·\n",
      "\n",
      "可以攻击 目标·\n",
      "\n",
      "。// 目标·\n",
      "\n",
      "是一个 战舰·\n",
      "\n",
      "。// 航空母炮·\n",
      "\n",
      "可以攻击 艇队·\n",
      "\n",
      "。// 艇队·\n",
      "\n",
      "是一个 班队·\n",
      "\n",
      "。// 班队·\n",
      "\n",
      "是一个 艇队·\n",
      "\n",
      "。// 艇队·\n",
      "\n",
      "可以攻击 危险区域·\n",
      "\n",
      "。// 危险区域·\n",
      "\n",
      "是一个 地图区域·\n",
      "\n",
      "。// 地图区域·\n",
      "\n",
      "是一个 地图·\n",
      "\n",
      "。// 地图·\n",
      "\n",
      "是一个 地图。// 地图·\n",
      "\n",
      "可以进行 航空母炮·\n",
      "\n",
      "攻击。// 地图区域·\n",
      "\n",
      "是 航空母炮·\n",
      "\n",
      "攻击的目标。// 地图·\n",
      "\n",
      "是 地图区域·\n",
      "\n",
      "的容器。// 地图区域·\n",
      "\n",
      "是 危险区域·\n",
      "\n",
      "\n",
      "==================================================\n",
      "{'if_ours': False, 'name': 'Marine', 'health': 80, 'Position': {'x': 20, 'y': 30}}\n"
     ]
    }
   ],
   "source": [
    "# 单元格 2: 定义推理函数并生成内容\n",
    "\n",
    "def generate_content(model, tokenizer, prompt: str, entity_vector: list) -> str:\n",
    "    \"\"\"\n",
    "    使用已加载的模型和分词器生成内容。\n",
    "    \"\"\"\n",
    "    device = model.device\n",
    "\n",
    "    # --- 1. 准备输入 ---\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    input_ids = inputs.input_ids.to(device)\n",
    "    attention_mask = inputs.attention_mask.to(device)\n",
    "    entity_vector_tensor = torch.tensor(entity_vector, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "    # --- 2. 生成回复 ---\n",
    "    print(\"正在生成回复...\")\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            entity_vectors=entity_vector_tensor,\n",
    "            max_new_tokens=256,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            temperature=0.7,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "\n",
    "    # --- 3. 解码并返回结果 ---\n",
    "    response = tokenizer.decode(output_ids[0][input_ids.shape[1]:], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "# --- 准备推理数据 ---\n",
    "# test_prompt = (\n",
    "#     \"\"\"<sc2_entity>\\nThis is an entity in a StarCraft scene. The entity's attributes include:\\n1.  Whether it is a friendly entity\\n2.  The entity's name\\n3.  The entity's health points\\n4.  The entity's position\\n\\nPlease output the entity's attributes in a structured way.\\nExample: [True, # Friendly entity, if not a friendly entity then it is False\\n\\\"xxxxx\\\", # The entity's name\\n100, # The entity's health points\\n{\\\"x\\\": 10, \\\"y\\\": 20}] # The entity's position\\n\"\"\"\n",
    "# )\n",
    "\n",
    "test_prompt = (\n",
    "    \"<sc2_entity>\\n 以上是一个 星际争霸场景的entity，请你描述一下 这个entity的状态\"\n",
    ")\n",
    "\n",
    "print(f\"实体向量维度: {config.ENTITY_VECTOR_DIM}\")\n",
    "# test_entity_vector = np.random.rand(config.ENTITY_VECTOR_DIM).tolist()\n",
    "test_entity_vector = data[\"encode\"]\n",
    "\n",
    "# --- 执行推理 ---\n",
    "response = generate_content(model, tokenizer, test_prompt, test_entity_vector)\n",
    "\n",
    "# --- 打印结果 ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"输入 Prompt:\")\n",
    "print(test_prompt)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"模型生成结果:\")\n",
    "print(response)\n",
    "print(\"=\"*50)\n",
    "print(data[\"text_dict\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
